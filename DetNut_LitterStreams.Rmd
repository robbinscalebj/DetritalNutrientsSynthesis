---
title: "DetNut_LitterStreams"
author: "CJR"
date: "2/27/2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(assertr)
library(janitor)
library(mgcv)
library(gratia)
library(tidymv)

```

```{r Set working directory}
#Use the test directory on the Desktop
DetNut_Files<-list.files("/Users/robbi/Dropbox/Detrital Nutrients Synth/Synthesis Data txt Files", full.names = TRUE) #Obviously change this to where you need to
head(DetNut_Files)

```
#Whole set ingest and carpentry
```{r Read files}
DetNut<-DetNut_Files%>%
  map(~read_tsv(.x, col_types = cols(First_Author = "c",
                                     Title = "c",
                                     Year = "c",
                                     Journal = "c",
                                     DOI = "c",
                                     System = "c",
                                     Flow_Category = "c",
                                     Decay_Method = "c",
                                     Mesh_Size_Category = "c",
                                     Setting = "c",
                                     Manipulation = "c",
                                     LULC_Category = "c",
                                     Light_Category = "c",
                                     Detritus_Type = "c",
                                     Detritus_Condition = "c",
                                     Detritus_Species = "c",
                                     Remain_Mass_Category = "c",
                                     Component_Mass_Category = "c",
                                     Geog_Locale = "c",
                                     LULC_Quantified = "c",
                                     Inverts_AddInfo = "c",
                                     Microbes_AddInfo = "c",
                                     CNPFluxes_AddInfo = "c",
                                     C_Method = "c", 
                                     N_Method = "c",
                                     P_Method = "c", 
                                     Ratio_Type = "c",
                                     Notes = "c",
                                     .default = "n"))
         )

names(DetNut) <- DetNut_Files%>%
  str_remove("/Users/robbi/Dropbox/Detrital Nutrients Synth/Synthesis Data txt Files/")


```

```{r}
DetNut2 <- DetNut%>%
  map_df(as_tibble)%>%
  select(-X59,-X60)%>%
  select(-60)%>%
  remove_empty(which = "rows")%>%
  mutate(Remain_Mass_Category = fct_recode(Remain_Mass_Category, dm = "dry_mass", afdm_postleach = "AFDM_postleach", afdm = "AFDM", dm = "DM"))
  
  


```


Next code groups by individual time series (again, likely some preliminary errors here, but OK for now) and creates some new variables that will be helpful in analysis, and makes it into a new dataframe (DetNut.ts) that can be used for data visualization and analysis. A lot of these use 'case_when' to denote particular conditions when a variable should be mutated (e.g., leave the variable alone if it's not NA, but create an approximate alternative from other variables when possible)
```{r}
#treat time series for analysis - what's the grouping structure? First_Author, Title, and Time_Series ID? Need to make an index number for EACH TIME SERIES

DetNut.ts <- DetNut2%>%
  group_by(First_Author, Title, Time_Series_ID)%>%
  mutate(series_index = group_indices())%>%#creates a unique index for each time series
  ungroup()%>%
  group_by(series_index)%>% #functionally, used to confine any window functions like first() to a time series rather than the first observation of whole dataframe
  mutate(initial_C = first(C_per),
         initial_N = first(N_per),
         initial_P = first(P_per),
         initial_CN = first(CN_molar),
         initial_CP = first(CP_molar),
         initial_NP = first(NP_molar),
         initial_Lignin = first(Lignin_per))%>%
  #next bit creates fairly even distribution of initial N categories
  mutate(initial_N_category = case_when(initial_N>2.5 ~ "high >2.5",
                                initial_N>1.5 & initial_N <= 2.5 ~ "med-high 1.5 -2.5",
                                initial_N>1.1 & initial_N <= 1.5 ~ "med 1.1-1.5",
                                initial_N>0.75 & initial_N <= 1.1 ~ "low-med 0.75-1.1",
                              initial_N <= 0.75~ "Low <0.75"))%>%
  #next normalizes CNP values to initial measurements for each time series (don't know if useful for stoich but did it anyway)
  mutate(C_prop_initial = C_per/first(C_per),
         N_prop_initial = N_per/first(N_per),
         P_prop_initial = P_per/first(P_per),
         CN_prop_initial = CN_molar/first(CN_molar),
         CP_prop_initial = CN_molar/first(CP_molar),
         NP_prop_initial = CN_molar/first(NP_molar))%>%
  mutate(Detritus_Type = case_when(Detritus_Type == "leaf" |Detritus_Type == "leaf_disk" |Detritus_Type == "plant_leaves" |Detritus_Type == "leave_disks" |Detritus_Type == "Leaves" ~ "leaves",
                                   TRUE ~ Detritus_Type))%>%
  #next approximates percent mass remaining (if not provided) at each measurement day from k value
  mutate(Mass_per_remaining = case_when(is.na(Mass_per_remaining) & Remain_Mass_Category == "afdm" ~ exp(-k*Meas_Day)*100,
                                        is.na(Mass_per_remaining) & Remain_Mass_Category == "dm" ~ exp(-k*Meas_Day)*100,
                                        TRUE ~ Mass_per_remaining))%>%
  #next develops an approximation of N and P availability - imperfect, but aggregates the N and P data together about as well as possible without assuming anything else
  mutate(Water_DIN_ug.L = case_when(is.na(Water_DIN_ug.L) & is.na(Water_NH4_ug.L) ~ Water_NO3_ug.L,
                                    is.na(Water_DIN_ug.L) ~ Water_NO3_ug.L + Water_NH4_ug.L,
                                    TRUE ~ Water_DIN_ug.L),
         TN_approx = case_when(is.na(Water_TN_ug.L) ~ Water_DIN_ug.L,
                               TRUE ~ Water_TN_ug.L),
         TP_approx = case_when(is.na(Water_TP_ug.L) ~ Water_SRP_ug.L,
                               TRUE ~ Water_TP_ug.L))%>%
  #next creates a Temperature, TN, and TP average when there are multiple values given - these NEEDS TO BE CHANGED INTO A TIME-WEIGHTED AVERAGE
  mutate(Temperature_C_avg = case_when(n_distinct(Temperature_C) >1 ~ mean(Temperature_C), 
                                       TRUE ~ Temperature_C),
         TN_approx_avg = case_when(n_distinct(TN_approx) >1 ~ mean(TN_approx), 
                                       TRUE ~ TN_approx),
         TP_approx_avg = case_when(n_distinct(TP_approx) >1 ~ mean(TP_approx), 
                                       TRUE ~ TP_approx))%>%
  mutate(Deg_days = Temperature_C * (Meas_Day-first(Meas_Day)))%>% #degree days
  #remove text from variable if not coarse fine or open
  mutate(Mesh_Size_Category = case_when(Mesh_Size_Category == "coarse" | Mesh_Size_Category == "fine" | Mesh_Size_Category == "open" ~ Mesh_Size_Category,
                              Mesh_Size_Category == "SRP" | is.na(Mesh_Size_Category) ~ "NA",
                              Mesh_Size_Category == 0 ~ "open",
                              TRUE ~ str_remove_all(Mesh_Size_Category, " mm|mm|_mm| |_1|-")))%>% 
  mutate(mesh_cat = case_when(Mesh_Size_Category == "coarse" | Mesh_Size_Category == "fine" | Mesh_Size_Category == "open" ~ Mesh_Size_Category,
                              Mesh_Size_Category < 1 ~ "fine",
                              Mesh_Size_Category >= 1 ~ "coarse"))%>%
  filter(Mass_per_remaining > 0)%>%
  mutate(Lotic_Lentic = case_when(System == "stream"|System == "Stream"|System == "Channel"|System == "river" ~ "Lotic",
                                  System == "wetland"|System == "Wetland"|System == "wetlands"|System == "lake"|System == "Lake"|System == "pond"|System == "reservoir" ~ "Lentic",
                                  TRUE ~ System))

#must use summarize to create missing k values from Mass_per_remaining

#DetNut.ts_k <- DetNut.ts%>%
#  group_by(series_index)%>%
#  summarize(k = )
  
  
#how to deal with postleach data - can only use when excluding leaching data, and then need to correct mass remaining values of non-leached to 100% on day 2ish if possible. Probably not worth using those postleach data but they are >100 data points, but mostly from 1 study. dm_postleach even smaller. Lots of NA under that, though. 



#Time-integrated conditions - already calculated degree days, but could do to approximate a cumulative N load, P load, etc.

unique(DetNut.ts$mesh_cat)


```

```{r}

DetNut.nest <- DetNut.ts%>%
  group_by(First_Author, Title, Journal, series_index, Detritus_Type, Velocity_m.s, mesh_cat, Decay_Method, initial_N, initial_P, initial_CN, initial_CP, initial_NP, initial_Lignin, initial_N_category, System, Lotic_Lentic, Detritus_Species, TN_approx_avg, TP_approx_avg, Detritus_Condition, Temperature_C_avg)%>%
  nest()%>%
  mutate(Series_Measurements = map_dbl(data, nrow),
         Detritus_Type = as_factor(Detritus_Type))%>%
  filter(Series_Measurements > 1)
 # mutate(Series_Length1 = attributes(data))
  #make a k value with many models stuff

  k_lm <- function(df) {
  lm(log(Mass_per_remaining) ~ Meas_Day, data = df)
  }

  
DetNut.nest<-DetNut.nest%>%
  mutate(k_model = map(data, k_lm))%>%
  mutate(k_model = map(k_model, broom::tidy))%>%
  mutate(k_model = map(k_model, ~filter(., term == "Meas_Day")))%>%
  mutate(k_model = map_dbl(k_model, ~pluck(., "estimate")*-1))%>%
  mutate(K_model_degday = k_model/Temperature_C_avg)%>%
  mutate(Series_Days = map_dbl(data, ~last(.$Meas_Day, order_by = .$Meas_Day)))%>%
  mutate(Lignin_N = initial_Lignin/initial_N)

DetNut.ts2 <- DetNut.nest%>%
  unnest()


DetNut_species<- DetNut.nest%>%
  ungroup()%>%
  summarize(n_species = n_distinct(Detritus_Species))

DetNut_types<- DetNut.nest%>%
  ungroup()%>%
  count(Detritus_Type)%>%
  mutate(proportion = n/sum(n))

DetNut_systems<- DetNut.nest%>%
  ungroup()%>%
  count(System)%>%
  mutate(proportion = n/sum(n))

DetNut_systemstypes<- DetNut.nest%>%
  ungroup()%>%
  count(System, Detritus_Type)%>%
  mutate(proportion = n/sum(n))
 
DetNut_systemstypescond<- DetNut.nest%>%
  ungroup()%>%
  count(System, Detritus_Type, Detritus_Condition)%>%
  mutate(proportion = n/sum(n))

DetNut_ncat<- DetNut.nest%>%
  ungroup()%>%
  filter(!is.na(initial_N))%>%
  count(initial_N_category)%>%
  mutate(proportion = n/sum(n))

DetNut.nest%>%
  ggplot(aes(x = Series_Days))+
  geom_histogram()

```

#Pare down to stream-litter
```{r}
#litter_lotic for analysis of time series
litter_lotic <- DetNut.ts%>%
  filter(Lotic_Lentic == "Lotic" & Detritus_Type == "leaves")%>%
  filter(mesh_cat != "open")%>%
  filter(TP_approx_avg <250 & TN_approx_avg <5000)%>%
  ungroup()%>%
  group_by(series_index)%>%
  mutate(Series_Measurements = NROW(N_per))%>%
  filter(Series_Measurements > 1)%>%
  filter(Mass_per_remaining > 15)%>%
  mutate(postleach_category = case_when(Remain_Mass_Category == "afdm" | Remain_Mass_Category == "dm" ~ "preleach",
                                        Remain_Mass_Category == "afdm_postleach" ~ "postleach"))%>%
  mutate(series_index = as_factor(series_index),
         Mass_per_loss = 100-(Mass_per_remaining),
         initial_N_category = as_factor(initial_N_category),
         mesh_cat = as_factor(mesh_cat),
         Remain_Mass_Category = as_factor(Remain_Mass_Category))

litter_lotic_postleach <- litter_lotic%>%
    filter(case_when(postleach_category == "preleach" ~ Meas_Day >=2,
                   postleach_category == "postleach" ~ Meas_Day >=0))%>%
    #filter(CN_molar>0 & !is.na(CN_molar))%>%
    mutate(initial_CN_category = case_when(initial_CN>100 ~ "high ",
                                initial_CN>75 & initial_CN <= 100 ~ "med-high ",
                                initial_CN>50 & initial_CN <= 75 ~ "med ",
                                initial_CN>25 & initial_CN <= 50 ~ "low-med ",
                              initial_CN <= 25~ "Low "),
           initial_CN_category = as_factor(initial_CN_category))

#litter_lotic.nest for analysis of aggregated variables with k and also description of time series
litter_lotic.nest <- DetNut.nest%>%
  filter(Lotic_Lentic == "Lotic" & Detritus_Type == "leaves")%>%
  filter(mesh_cat != "open")%>%
  filter(TP_approx_avg <250 & TN_approx_avg <5000)%>%
  filter(K_model_degday < 0.005)

```


#Breakdown
```{r}
litter_lotic.nest%>%
  #filter(K_model_degday <0.004)%>%
  #filter(initial_N < 3)%>%
  #filter(initial_P < 0.25)%>%
  filter(mesh_cat != "open")%>%
  #filter(TP_approx_avg <250 & TN_approx_avg <5000)%>%
  ggplot(aes(x = Temperature_C_avg, y = k_model))+
  geom_point()+
  geom_smooth(method = "loess")

```
Competing models for breakdown

- what determines the rate at which litter moves through decomposition, its detrital ontogeny
```{r breakdown models kd}


m1<-lm(k_model ~ Temperature_C_avg*initial_N*mesh_cat*TN_approx_avg, data = litter_lotic.nest)
m2<-lm(k_model ~ Temperature_C_avg*initial_P*mesh_cat*TN_approx_avg, data = litter_lotic.nest)
m3<-lm(k_model ~ Temperature_C_avg*initial_CN*TN_approx_avg*mesh_cat, data = litter_lotic.nest)
m4<-lm(k_model ~ Temperature_C_avg*initial_CP*mesh_cat*TP_approx_avg, data = litter_lotic.nest)


#summary(m1)
#summary(m2)
summary(m3)
#summary(m4)
#show temp depdencen and then say ok what outside of that variation due to temperature?
```

```{r breakdown models kdd}
m1<-lm(K_model_degday ~ initial_N*TN_approx_avg*mesh_cat, data = litter_lotic.nest)
m2<-lm(K_model_degday ~ initial_N*TP_approx_avg*mesh_cat, data = litter_lotic.nest)
m3<-lm(K_model_degday ~ initial_P*TN_approx_avg*mesh_cat, data = litter_lotic.nest)
m4<-lm(K_model_degday ~ initial_P*TP_approx_avg*mesh_cat, data = litter_lotic.nest)
m5<-lm(K_model_degday ~ initial_CN*TN_approx_avg*mesh_cat, data = litter_lotic.nest)
m6<-lm(K_model_degday ~ initial_CN*TP_approx_avg*mesh_cat, data = litter_lotic.nest)
m7<-lm(K_model_degday ~ initial_CP*TN_approx_avg*mesh_cat, data = litter_lotic.nest)
m8<-lm(K_model_degday ~ initial_CP*TP_approx_avg*mesh_cat, data = litter_lotic.nest)
m9<-lm(K_model_degday ~ initial_NP*TN_approx_avg*mesh_cat, data = litter_lotic.nest)
m10<-lm(K_model_degday ~ initial_NP*TP_approx_avg*mesh_cat, data = litter_lotic.nest)


m.list <- list(m1,m2,m3,m4,m5,m6,m7,m8,m9,m10)

m.r2<-map(m.list, glance)%>%
  map(., ~pluck(., "r.squared"))

#m7 and m8 best models, basically equivalent

summary(m7)

ggplot()+
plot(resid(m7), as_factor(litter_lotic.nest$mesh_cat), na.action = na.omit)
#plot(resid(m7), litter_lotic.nest$TN_approx_avg, na.action = na.omit)
#plot(resid(m7), litter_lotic.nest$initial_CP)
```

Shift is - going from holistic process of breakdown to 

Competing GAMs for N and P ontogenetic patterns
Common to start with initial proportion - evolution from 1, a normalized starting point. 

N categories as factors whose shape is allowed to vary
N_prop_initial ~ Mass_per_remaining - breakdown rate alone best predictor (say, no it turns out that evolution of N content in litter follows different paths based on initial litter quantities of N) --- or not for P
N_prop_initial ~ initial N + Mass_per_remaining + mesh cat  - by mass model
N_prop_initial ~ initial N + Meas_day + Temperature - by time model

Combining these ideas about breakdown rates and N availability says a lot about the persistence of these resources in systems and routing to different ecosystem pathways - N mass through time. 

```{r plot N series}

litter_lotic_postleach%>%
  ggplot(aes(x = Mass_per_loss, y = N_prop_initial, color = initial_N_category))+
  geom_point()+
  geom_smooth(method = "loess")+
  xlim(c(0,100))

litter_lotic_postleach%>%
  ggplot(aes(x = Mass_per_loss, y = N_per, color = initial_N_category))+
  geom_point()+
  geom_smooth(method = "loess")+
  xlim(c(0,100))+
  facet_wrap(.~initial_N_category)

litter_lotic_postleach%>%
  ggplot(aes(x = Meas_Day, y = N_per*Mass_per_remaining, color = initial_N_category))+
  geom_point()+
  geom_smooth(method = "loess")+
  xlim(c(0,100))+
  facet_wrap(.~initial_N_category)
  

```

```{r N GAM}
#N_null.gam <- gam(N_prop_initial ~ s(Mass_per_loss, k = 5)+s(series_index, bs = "re"), data = litter_lotic)
#summary(N_null.gam)
#draw(N_null.gam)
#gam.check(N_null.gam)

#this model is OK
#N_Ncat.gam1 <- gam(N_prop_initial ~ s(Mass_per_loss, initial_N_category, bs = "fs", k = 30) + s(initial_N_category, bs = "re"), data = litter_lotic_postleach, family = Gamma(link = "log"))

#N_Ncat.gam1 <- gam(N_prop_initial ~ te(Mass_per_loss, initial_N, k = 5), data = litter_lotic_postleach, family = Gamma(link = "log"))

summary(N_Ncat.gam1)
draw(N_Ncat.gam1)
gam.check(N_Ncat.gam1)
qq.gam(N_Ncat.gam1, rep = 500)
#k.check(N_Ncat.gam)
#anova(N_Ncat.gam, N_Ncat.gam2)
```

```{r plot N models}
#predict_gam to exclude random effects
#exclude_terms = "s(Mass_per_loss,initial_N_category)", values = list(series_index = NULL)
pred_Ncat<-predict_gam(N_Ncat.gam1)

ggplot()+
 geom_smooth(data = pred_Ncat, aes(Mass_per_loss, y = exp(fit), color = initial_N_category), size = 2)+
  geom_point(data = litter_lotic_postleach, aes(Mass_per_loss, N_prop_initial, color = initial_N_category), alpha = 0.25)+
  xlim(c(0,100))+
  ylim(c(0.0,4.0))+
  facet_wrap(.~initial_N_category)+
  NULL



```

Through the decomposition process the initial N really seems to be the major driver of timing a shift toward net mineralization - in fact though it's likely rarely observed in individual studies. 

It's actually rather fascinating that we see such similarities across terrestrial and aquatic studies, even with the variation and uncertainty here. There are absolutely fundamental differences between  

Main differences with Parton - aquatic litter more retentive of N at later decomposition stages - part of this is methodological - late stages of breakdown in aquatic systems earlier in decomposition. 


```{r plot CN series}

litter_lotic_postleach%>%
  ggplot(aes(x = Mass_per_loss, y = CN_molar))+
  geom_point()+
  geom_smooth(method = "loess")+
  xlim(c(0,100))

litter_lotic_postleach%>%
  filter(!is.na(initial_CN_category))%>%
  ggplot(aes(x = Mass_per_loss, y = CN_molar, color = initial_CN_category))+
  geom_point()+
  geom_smooth(method = "loess")+
  xlim(c(0,100))
  

```

```{r GAM C:N}
CN_fs.gam <- gam(CN_molar ~ s(Mass_per_loss, initial_CN_category, bs = "fs"), data = litter_lotic_postleach, family = Gamma(link = "log"))

summary(CN_fs.gam)
draw(CN_fs.gam)
gam.check(CN_fs.gam)
qq.gam(CN_fs.gam, rep = 500)

```

```{r plot GAM}

pred_CNcat<-predict_gam(CN_fs.gam)

ggplot()+
 geom_smooth(data = pred_CNcat, aes(Mass_per_loss, y = exp(fit), color = initial_CN_category), size = 2)+
  geom_point(data = litter_lotic_postleach, aes(Mass_per_loss, CN_molar, color = initial_CN_category), alpha = 0.25)+
  #xlim(c(0,100))+
  #ylim(c(0.0,4.0))+
  facet_wrap(.~initial_CN_category)+
  NULL

```

Do same stuff for P
Look at NP ratios

