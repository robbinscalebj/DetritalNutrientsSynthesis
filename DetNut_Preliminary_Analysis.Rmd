---
title: "DetNut Preliminary Analysis"
author: "CJR"
date: "1/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(gratia)
library(mgcv)
library(tidymv)

```

```{r data ingest}


det_raw <- read_csv("C:\\Users\\robbi\\Dropbox\\Detrital Nutrients Synth\\DetNutSynth_Database.csv")

```



```{r create new summary variables, include=FALSE}
det <- det_raw%>%
  group_by(First_Author, Publication_Title, Time_Series_ID)%>%
  mutate(series_index = group_indices())%>%#creates a unique index for each time series
  ungroup()%>%
  group_by(series_index)%>% #functionally, used to confine any window functions like first() to a time series rather than the first observation of whole dataframe
  mutate(initial_C = first(C_per),
         initial_N = first(N_per),
         initial_P = first(P_per),
         initial_CN = first(CN_ratio),
         initial_CP = first(CP_ratio),
         initial_NP = first(NP_ratio),
         initial_Lignin = first(Lignin_per))%>%
  #next normalizes CNP values to initial measurements for each time series and to initial masses as in Manzoni
  mutate(C_prop_initial = C_per/first(C_per),
         N_prop_initial = N_per/first(N_per),
         P_prop_initial = P_per/first(P_per),
         C_mass = ((C_per/100)*Mass_per_remaining),
         N_mass = ((N_per/100)*Mass_per_remaining),
         P_mass = ((P_per/100)*Mass_per_remaining),
         C_mass_norm = ((C_per/100)*Mass_per_remaining)/(first(C_per/100)*first(Mass_per_remaining)),
         N_mass_norm = ((N_per/100)*(Mass_per_remaining/100))/((first(N_per)/100)*first(Mass_per_remaining/100)),
         P_mass_norm = ((P_per/100)*Mass_per_remaining)/(first(P_per/100)*first(Mass_per_remaining)))%>%


  #next approximates percent mass remaining (if not provided) at each measurement day from k value
  mutate(Mass_per_remaining = case_when(is.na(Mass_per_remaining) & Remain_Mass_Category == "afdm" ~ exp(-k*Meas_Day)*100,
                                        is.na(Mass_per_remaining) & Remain_Mass_Category == "dm" ~ exp(-k*Meas_Day)*100,
                                        TRUE ~ Mass_per_remaining))%>%
  #next develops an approximation of N and P availability - imperfect, but aggregates the N and P data together about as well as possible without assuming anything else
  mutate(Water_DIN_ug.L = case_when(is.na(Water_DIN_ug.L) & is.na(Water_NH4_ug.L) ~ Water_NO3_ug.L,
                                    is.na(Water_DIN_ug.L) ~ Water_NO3_ug.L + Water_NH4_ug.L,
                                    TRUE ~ Water_DIN_ug.L),
         TN_approx = case_when(is.na(Water_TN_ug.L) ~ Water_DIN_ug.L,
                               TRUE ~ Water_TN_ug.L),
         TP_approx = case_when(is.na(Water_TP_ug.L) ~ Water_SRP_ug.L,
                               TRUE ~ Water_TP_ug.L))%>%
  #next creates a Temperature, TN, and TP average when there are multiple values given - these NEEDS TO BE CHANGED INTO A TIME-WEIGHTED AVERAGE
  mutate(Temperature_C_avg = case_when(n_distinct(Temperature_C) >1 ~ mean(Temperature_C), 
                                       TRUE ~ Temperature_C),
         TN_approx_avg = case_when(n_distinct(TN_approx) >1 ~ mean(TN_approx), 
                                       TRUE ~ TN_approx),
         TP_approx_avg = case_when(n_distinct(TP_approx) >1 ~ mean(TP_approx), 
                                       TRUE ~ TP_approx))%>%
  mutate(Deg_days = Temperature_C * (Meas_Day-first(Meas_Day)))%>% #degree days
  #remove text from variable if not coarse fine or open

  mutate(mesh_cat = case_when(Mesh_Size_Category == "coarse" | Mesh_Size_Category == "fine" | Mesh_Size_Category == "open" ~ Mesh_Size_Category,
                              Mesh_Size_Category < 1 ~ "fine",
                              Mesh_Size_Category >= 1 ~ "coarse"))%>%
 
  mutate(Lotic_Lentic = case_when(System == "stream"|System == "Stream"|System == "Channel"|System == "river" ~ "Lotic",
                                  System == "wetland"|System == "Wetland"|System == "wetlands"|System == "marsh"|System == "lake"|System == "Lake"|System == "pond"|System == "reservoir" ~ "Lentic",
                                  TRUE ~ System),
         Lotic_Lentic = as_factor(Lotic_Lentic))%>%

  mutate(cum_TN = cumsum(TN_approx_avg)*Meas_Day,
         cum_TP = cumsum(TP_approx_avg)*Meas_Day)%>%
  mutate(series_index = as_factor(series_index),
         Mass_per_loss = 100-(Mass_per_remaining),
         mesh_cat = as_factor(mesh_cat),
         Remain_Mass_Category = as_factor(Remain_Mass_Category))


```

```{r trim data}
det_trim<-det%>%
  filter(Mass_per_remaining<=100)%>%
  filter(Mass_per_remaining >=20)%>%
  filter(initial_N <3)%>%
  filter(!is.na(N_mass_norm))%>%
  filter(N_mass_norm != 0)%>%
  mutate(weights = ifelse(Mass_per_loss == 0, 1e6, 1))%>%
  filter(Detritus_Type == "leaves")%>%
  filter(Detritus_Condition == "senesced")%>%
  filter(Remain_Mass_Category == "dm"|Remain_Mass_Category == "afdm")%>%
  filter(mesh_cat != "open")%>%
  mutate(Remain_Mass_Category = fct_drop(Remain_Mass_Category, only = c("dm_postleach", "afdm_postleach", "organic_carbon")))%>%
  mutate(mesh_cat = fct_drop(mesh_cat, "open"))%>%
  ungroup()

levels(det_trim$Remain_Mass_Category)
levels(det_trim$mesh_cat)


```

#Modeling Framework
We will use our dataset to establish and explore empirical patterns of detrital nutrient content and stoichiometry, and to base future research needs. We can use GAMs to model non-linear patterns (hypothesized based on terrestrial and some aquatic theory). Modeling will highlight patterns but also limits of our dataset, which we can use to define future research objectives.


We explicitly hypothesize that nutrient-mass loss curves are non-linear, strongly predicted by initial nutrient content, and curve inflections are related to initial nutrient content. Exploratory analysis, when possible, should focus on potential alternative factors that predict (or additionally predict) observed patterns beyond initial nutrient content. Other predictors should be tested with and without initial nutrient content - even if not enough data to look at additional predictors (suggests future research), can rule out other models. Additional predictors include Temperature, external N, external P, velocity...

Specifically, the GAMs will have some mixed effects, to model 'subject-specific' (i.e., each time series) trends. This means a random slope - we need not model a  random intercept because the N_mass_loss data all start at a known point - each series starting point is normalized to 1. If we model unnormalized N mass as a response, we may want to include  random intercept. 


#N modeling
##Lotic Coarse N mass-initial N models
We could use 'by' variables to analyze models along a Lotic_Lentic split (i.e., lotic/lentic would be factor within a single model), but this adds considerable complexity within our modeling framework, particularly during exploratory analysis. Preliminary data visualization/exploration shows these categories are very different in terms of numbers of observations, and I think presenting and discussing qualitative differences between realms will suffice. Note that there are not enough data within the lentic-fine category to fit this GAM structure, but we can visualize it below.



```{r Lotic-Coarse global N loss model}

det_loc <- det_trim%>%
  filter(mesh_cat == "coarse", Lotic_Lentic == "Lotic")%>%
  mutate(N_bin = cut_number(initial_N, n = 5))%>%mutate(N_bin = as_factor(N_bin))
  #filter(Mass_per_loss>0) #was worried about all the points at 0,1 inflating the R^2 (is that a thing?) but the effect is very small in removing vs retaining


#base model - global change in N mass curves - includes random slope, but not random intercept - uniform intercept desirable
#after tinkering, Gamma distro with inverse link function yields best residuals
N.loc.rs <- gam(data = det_loc, N_mass_norm ~ s(Mass_per_loss, k = 15) + s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "inverse"))
summary(N.loc.rs)
appraise(N.loc.rs)
draw(N.loc.rs)
k.check(N.loc.rs)

gam_pred<-predict_gam(N.loc.rs, exclude_terms =  "s(series_index,Mass_per_loss)",length_out = 1000, values = list(series_index = NULL))
 N.loc.rs.p<- ggplot()+
  geom_point(data = det_loc, aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_smooth(data = gam_pred, se = FALSE, aes(x = Mass_per_loss, y = 1/fit))+
    geom_abline(slope = -0.01, intercept = 1)+
    geom_ribbon(data = gam_pred, aes(x = Mass_per_loss, ymin = 1/(fit -2*se.fit), ymax = 1/(fit +2*se.fit)), alpha = 0.3)+
    NULL
 N.loc.rs.p
  
```
Overall this model isn't too bad, and explains a lot of variation, ~90%, but that's really inflated by inclusion of random effects. It also suggests that N loss is non-linear, though it doesn't seem super wiggly when plotted.

We can check if mass category is potentially causing interpretation problems.The main way to handle this is as a factor-smooth interaction between mass loss and mass category (can't use random effects because only two levels of mass category - need ~5 to be reliable)
```{r Lotic-Coarse Check Mass category problems}

N.loc.rs2 <- gam(data = det_loc, N_mass_norm ~ s(Mass_per_loss, k = 15) + s(series_index, Mass_per_loss, bs = "re") + s(Remain_Mass_Category, Mass_per_loss, bs = "fs"), select= TRUE, method = "REML", family = Gamma(link = "log"))
summary(N.loc.rs2)
appraise(N.loc.rs2)
k.check(N.loc.rs2)
#can't draw() with factor like this


gam_pred<-predict_gam(N.loc.rs2, exclude_terms = c("s(series_index,Mass_per_loss)","s(Remain_Mass_Category, Mass_per_loss)"),values = list(series_index = NULL))
 N.loc.rs2.p<- ggplot()+
  geom_point(data = det_loc, aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_smooth(data = gam_pred, se= FALSE, aes(x = Mass_per_loss, y = 1/fit))+
    geom_abline(slope = -0.01, intercept = 1)+
    #facet_grid(.~Remain_Mass_Category)+
    #geom_ribbon(data = gam_pred, aes(x = Mass_per_loss, ymin = 1/(fit -2*se.fit), ymax = 1/(fit +2*se.fit)), alpha = 0.3)+
    NULL
N.loc.rs2.p
  
AIC(N.loc.rs,N.loc.rs2)
```
There's good reason to suspect that Mass category affects these curves - factor smooth term is significant, and a substantial reduction in AIC on model comparison. Looking at the plotted curves, DM curves tend to lose proportionally less N through time. My guess is that's a function of mass loss being underestimated at those time points in comparison to AFDM - this may be a signal from inorganic matter becoming an increasingly larger proportion of mass throughout decomposition (i.e., the x axis doesn't mean the same thing between dm and afdm samples). The good news is now we can retain this in our models to 1. 'control' for it. 

 
## N Mass lotic exploratory modeling
 So what might explain some of the variation during mass loss? We can keep these models relatively simple for three primary reasons: 1) Interactions in GAMs may become intractable and difficult to interpret, 2) The more covariates included in a single model, the fewer observations from which to estimate effects (this also presents problems for model selection, 3) within endogenous and exogenous categories, covariates might be correlated (e.g., initial_N and initial_Lignin are correlated). We simply have to be careful about how we interpret the significance here - it is exploratory modeling into 'global'-level trends. Our focus is on how curves change along Mass Loss, so this is fundamentally a question about tensor smooth interactions (i.e., interactions between mass loss and a covariate on the response variable; ti(Mass_per_loss, Covariate)). We will avoid three-way tensor interactions. Honestly this largely turns into a bivariate correlational analysis that controls for random slopes/group correlation and methodological (dm vs afdm measures) constraints - that is, we're just looking for how N mass curves are affected by single exogenous and endogenous factors, and I think that's fine. 
 
 Model structures are constrained to fitting random slope/intercept (except: 1) if not possible/too complex for data, 2) redundancy with intercept)
 Model selection is based on satisfying residuals and comparing AIC values - comparing models with different distributional assumptions only. Sensible options include Gamma and gaussian/normal distros, with log, inverse, and identity links - so comparing 6 models for each covariate
 Model inference is based on p values (note select = TRUE option) of explored covariates, and plots of model predictions
 
 Exogenous, endogenous, and methodological exploratory models informed combination models 
 
 We should quickly plot histograms of our covariates just to understand their variation. I'm not aware of reasons to transform covariates (as opposed to the response, which we handle by changing the distributional assumption in the model), but interesting to look at these
 
```{r Histogram covariates}
ggplot(data = det_loc, aes(x = Velocity_m.s))+
  geom_histogram()
ggplot(data = det_loc, aes(x = Temperature_C))+
  geom_histogram()
ggplot(data = det_loc, aes(x = TN_approx_avg))+
  geom_histogram()
ggplot(data = det_loc, aes(x = TP_approx_avg))+
  geom_histogram()
ggplot(data = det_loc, aes(x = log(TN_approx_avg/TP_approx_avg)))+
  geom_histogram()


ggplot(data = det_loc, aes(x = initial_N))+
  geom_histogram()
ggplot(data = det_loc, aes(x = initial_P))+
  geom_histogram()
ggplot(data = det_loc, aes(x = initial_Lignin))+
  geom_histogram()
ggplot(data = det_loc, aes(x = (initial_N/initial_P)*(31/14)))+
  geom_histogram()

ggplot(data = det_loc, aes(x = Ergosterol_ug.g))+
  geom_histogram()
 
```

```{r Lotic Coarse exploratory models - Endo models}

#modeling initial_N as fixed effect or series_index as random intercept = equivalent models. 
N.end.n1 <- gam(data = det_loc, N_mass_norm ~  te(initial_N,Mass_per_loss, m = 2) + te(initial_N,Mass_per_loss,by=Remain_Mass_Category) +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "identity"),select = TRUE) 

N.end.n2 <- gam(data = det_loc, N_mass_norm ~  te(initial_N,Mass_per_loss, m = 2) + te(initial_N,Mass_per_loss,by=Remain_Mass_Category) +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "inverse"),select = TRUE) 


N.end.n3 <- gam(data = det_loc, N_mass_norm ~  te(initial_N,Mass_per_loss, m = 2) + te(initial_N,Mass_per_loss,by=Remain_Mass_Category) +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "log"),select = TRUE) 

N.end.n4 <- gam(data = det_loc, N_mass_norm ~  te(initial_N,Mass_per_loss, m = 2) + te(initial_N,Mass_per_loss,by=Remain_Mass_Category) +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "identity"),select = TRUE) 

N.end.n5 <- gam(data = det_loc, N_mass_norm ~  te(initial_N,Mass_per_loss, m = 2) + te(initial_N,Mass_per_loss,by=Remain_Mass_Category) +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "inverse"),select = TRUE) 

N.end.n6 <- gam(data = det_loc, N_mass_norm ~  te(initial_N,Mass_per_loss, m = 2) + te(initial_N,Mass_per_loss,by=Remain_Mass_Category) +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "log"),select = TRUE) 


N.end.names <- list(N.end.n1, N.end.n2, N.end.n3,N.end.n4,N.end.n5,N.end.n6)
map(N.end.names, ~AIC(.)) #2 best by AIC, next is 3
map(N.end.names, ~appraise(.))  #residuals a bit heterscedastic on all
map(N.end.names, ~k.check(.)) #all good
map(N.end.names, ~summary(.)) #Best model has a significant ti term. Second best model has very weak ti term, and not very different from the average trend along mass loss.All other models have sig ti terms

gam_pred_ni<-predict_gam(type = "link", N.end.n2, length_out = 1000,  exclude_terms = c("s(series_index)", "s(series_index, Mass_per_loss)"), values = list(series_index = NULL,Remain_Mass_Category = NULL, initial_N = c(0.5,0.8,1.1,1.4,1.7,2.0)))%>%
  mutate(initial_N = as_factor(initial_N))

 N.ni.p<- ggplot()+
  geom_point(data = det_loc, aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_smooth(data = gam_pred_ni,se = FALSE, aes(x = Mass_per_loss, y = 1/fit, color = initial_N))+
    #geom_abline(slope = -0.01, intercept = 1)+
    #facet_grid(initial_N~.)+
    #geom_ribbon(data = gam_pred_ni, aes(x = Mass_per_loss, ymin = 1/(fit - 2*se.fit), ymax = 1/(fit - 2*se.fit)), alpha = 0.3)+
    NULL
 N.ni.p
 
 #best model suggests that N is lost somewhat more quickly in higher initial N litters compared to lower. 


```

 
 
```{r Velocity analysis}
N.vel1 <- gam(data = det_loc, N_mass_norm ~  s(Mass_per_loss) + ti(Velocity_m.s,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")  +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "identity"),select = TRUE) 

N.vel2 <- gam(data = det_loc, N_mass_norm ~  s(Mass_per_loss) + ti(Velocity_m.s,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")  +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "inverse"),select = TRUE) 

N.vel2b <- gam(data = det_loc, N_mass_norm ~  s(Mass_per_loss) + t2(Velocity_m.s,Mass_per_loss,Remain_Mass_Category, bs = c("tp", "tp","re"))  +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "inverse"),select = TRUE) 

N.vel3 <- gam(data = det_loc, N_mass_norm ~  s(Mass_per_loss) + ti(Velocity_m.s,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")  +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "log"),select = TRUE) 

N.vel4 <- gam(data = det_loc, N_mass_norm ~  s(Mass_per_loss) + ti(Velocity_m.s,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")  +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "identity"),select = TRUE) 

N.vel5 <- gam(data = det_loc, N_mass_norm ~   s(Mass_per_loss) + ti(Velocity_m.s,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")  +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "inverse"),select = TRUE) 

N.vel6 <- gam(data = det_loc, N_mass_norm ~   s(Mass_per_loss) + ti(Velocity_m.s,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "log"),select = TRUE) 


N.vel.names <- list(N.vel1, N.vel2, N.vel3,N.vel4,N.vel5,N.vel6) #
map(N.vel.names, ~AIC(.)) #3 best AIC, then 2
map(N.vel.names, ~appraise(.)) # residuals a bit heteroscedastic, but not much to be done
map(N.vel.names, ~k.check(.)) # these are pretty data limited, k.check indicates problems with some predictors, but can't improve
map(N.vel.names, ~summary(.)) # Most models suggested ti was significant predictor

#Velocity plot
gam_pred_vel1<-predict_gam(type = "link", N.vel2b, length_out = 1000, exclude_terms = c("s(series_index)", "s(series_index, Mass_per_loss)", "s(Remain_Mass_Category, Mass_per_loss)"), values = list(Mass_Remain_Category = NULL, series_index = NULL, Velocity_m.s = c(0.05,0.1,0.2)))%>%
  mutate(Velocity_m.s = as_factor(Velocity_m.s))


 N.vel.p1<- ggplot()+
  geom_point(data = det_loc%>%filter(!is.na(Velocity_m.s))%>%mutate(discrete = factor(cut(Velocity_m.s, seq(0.025,0.3,by = 0.08)))), aes(Mass_per_loss, N_mass_norm, color = discrete), alpha = 0.3)+
    geom_smooth(data = gam_pred_vel1, se = FALSE, aes(x = Mass_per_loss, y = 1/fit, color = Velocity_m.s))+
    geom_abline(slope = -0.01, intercept = 1)+
    #facet_grid(velocity_m.s~tN_approx_avg)+
    #geom_ribbon(data = gam_pred, aes(x = Mass_per_loss, ymin = 1/(fit -2*se.fit), ymax = 1/(fit +2*se.fit)), alpha = 0.3)+
    NULL
N.vel.p1

#best model seems to suggest there are differences early on in N mass loss, with slower velocities accumulating more N. Data may be limiting in detecting the functional form of the relationship later in decomposition

```



```{r Temp analysis}
N.temp1 <- gam(data = det_loc, N_mass_norm ~  s(Temperature_C) + s(Mass_per_loss) + ti(Temperature_C,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "identity"),select = TRUE) 

N.temp2 <- gam(data = det_loc, N_mass_norm ~   te(Temperature_C,Mass_per_loss, m = 2) + te(Temperature_C,Mass_per_loss,by=Remain_Mass_Category) +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "inverse"),select = TRUE) 

N.temp2a <- gam(data = det_loc, N_mass_norm ~  s(Mass_per_loss) + ti(Temperature_C,Mass_per_loss, m = 2) + ti(Temperature_C,Mass_per_loss,by=Remain_Mass_Category)  +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "inverse"),select = TRUE) 



N.temp3 <- gam(data = det_loc, N_mass_norm ~  s(Temperature_C) + s(Mass_per_loss) + ti(Temperature_C,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = gaussian(link = "log"),select = TRUE) 

N.temp4 <- gam(data = det_loc, N_mass_norm ~  s(Temperature_C) + s(Mass_per_loss) + ti(Temperature_C,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "identity"),select = TRUE) 

N.temp5 <- gam(data = det_loc, N_mass_norm ~  s(Temperature_C) + s(Mass_per_loss) + ti(Temperature_C,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "inverse"),select = TRUE) 

N.temp6 <- gam(data = det_loc, N_mass_norm ~  s(Temperature_C) + s(Mass_per_loss) + ti(Temperature_C,Mass_per_loss)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "log"),select = TRUE) 


N.temp.names <- list(N.temp1, N.temp2, N.temp3,N.temp4,N.temp5,N.temp6)
map(N.temp.names, ~AIC(.)) #2 best AIC, then 3
map(N.temp.names, ~appraise(.)) # residuals mostly heteroscedastic, not much to be done
map(N.temp.names, ~k.check(.)) # these are pretty data limited, k.check indicates problems with some predictors, but can't improve
map(N.temp.names, ~summary(.)) # almost all models, ti not significant

#Velocity plot
gam_pred_temp1<-predict_gam(type = "link", N.temp2b, length_out = 1000,  exclude_terms = c("s(series_index)", "s(series_index, Mass_per_loss)", "s(Remain_Mass_Category, Mass_per_loss)"), values = list(Mass_Remain_Category = NULL, series_index = NULL, Temperature_C = c(8,13,20)))%>%
  mutate(Temperature_C = as_factor(Temperature_C))

 N.temp.p1<- ggplot()+
  geom_point(data = det_loc%>%filter(!is.na(Temperature_C)), aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_smooth(data = gam_pred_temp1, se = FALSE, aes(x = Mass_per_loss, y = 1/fit, color = Temperature_C))+
    geom_abline(slope = -0.01, intercept = 1)+
    #facet_grid(velocity_m.s~tN_approx_avg)+
   # geom_ribbon(data = gam_pred_temp1, aes(x = Mass_per_loss, ymin = 1/(fit -2*se.fit), ymax = 1/(fit +2*se.fit)), alpha = 0.3)+
    NULL
N.temp.p1

```

```{r TN analysis}

N.ext.tn <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, TN_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = Gamma(link = "inverse"))

N.ext.tn1 <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, TN_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = Gamma(link = "identity"))

N.ext.tn2 <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, TN_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")+s(series_index, bs = "re")  +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = Gamma(link="log"))

N.ext.tn3 <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, TN_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = gaussian(link="inverse"))

N.ext.tn4 <- gam(data = det_loc, N_mass ~ ti(Mass_per_loss, TN_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = gaussian(link="log"))

N.ext.tn5 <- gam(data = det_loc, N_mass ~ ti(Mass_per_loss, TN_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = gaussian(link="identity"))

AIC(N.ext.tn, N.ext.tn1, N.ext.tn2,N.ext.tn3,N.ext.tn4,N.ext.tn5) #model 2 clear by AIC, residuals not bad

N.ext.tp <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, TP_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = Gamma(link = "inverse"))

N.ext.tp1 <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, TP_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = Gamma(link = "identity"))

N.ext.tp2 <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, TP_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = Gamma(link="log"))

N.ext.tp3 <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, TP_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = gaussian(link="inverse"))

N.ext.tp4 <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, TP_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = gaussian(link="log"))

N.ext.tp5 <- gam(data = det_loc, N_mass ~ ti(Mass_per_loss, TP_approx_avg)  +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re") +s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = gaussian(link="identity"))

AIC(N.ext.tp, N.ext.tp1, N.ext.tp2,N.ext.tp3,N.ext.tp4,N.ext.tp5) #N.ext.tp 4 favored by AIC, residuals OK, next best model tp2/tp3, inferences are not different based on any of those models






#Temp plot

gam_pred_temp<-predict_gam(type = "link", N.ext.temp2,  exclude_terms = c("s(series_index)", "s(series_index, Mass_per_loss)", "s(Remain_Mass_Category, Mass_per_loss)"), values = list(series_index = NULL, Temperature_C = c(8,13,20)))%>%
  mutate(Temperature_C = as_factor(Temperature_C))

 N.temp.p<- ggplot()+
  geom_point(data = det_loc, aes(Mass_per_loss, N_mass), alpha = 0.3)+
    geom_smooth(data = gam_pred_temp, aes(x = Mass_per_loss, y = exp(fit), color = Temperature_C))+
    geom_abline(slope = -0.01, intercept = 1)+
    #facet_grid(velocity_m.s~tN_approx_avg)+
    #geom_ribbon(data = gam_pred, aes(x = Mass_per_loss, ymin = 1/(fit -2*se.fit), ymax = 1/(fit +2*se.fit)), alpha = 0.3)+
    NULL
N.temp.p

#plot_smooths(N.ext.temp2, exclude_terms = c("s(Remain_Mass_Category, Mass_per_loss)")) #exclude_random = TRUE by default

#TN plot

gam_pred_tn<-predict_gam(type = "link", N.ext.tn2,  exclude_terms = c( "s(series_index)", "s(series_index, Mass_per_loss)", "s(Remain_Mass_Category, Mass_per_loss)"), values = list(series_index = NULL, TN_approx_avg = c(200,1000,2000,5000)))%>%
  mutate(TN_approx_avg = as_factor(TN_approx_avg))

 N.tn.p<- ggplot()+
  geom_point(data = det_loc, aes(Mass_per_loss, N_mass), alpha = 0.3)+
    geom_smooth(data = gam_pred_tn, aes(x = Mass_per_loss, y = exp(fit), color = TN_approx_avg))+
    geom_abline(slope = -0.01, intercept = 1)+
    #facet_grid(velocity_m.s~tN_approx_avg)+
    #geom_ribbon(data = gam_pred, aes(x = Mass_per_loss, ymin = 1/(fit -2*se.fit), ymax = 1/(fit +2*se.fit)), alpha = 0.3)+
    NULL
N.tn.p



gam_pred_tp<-predict_gam(type = "link", N.ext.tp4,  exclude_terms = c("s(initial_N", "s(series_index)", "s(series_index, Mass_per_loss)", "s(Remain_Mass_Category, Mass_per_loss)"), values = list(series_index = NULL, TP_approx_avg = c(10,50,100,400)))%>%
  mutate(TP_approx_avg = as_factor(TP_approx_avg))

 N.tp.p<- ggplot()+
  geom_point(data = det_loc, aes(Mass_per_loss, N_mass), alpha = 0.3)+
    geom_smooth(data = gam_pred_tp, aes(x = Mass_per_loss, y = exp(fit), color = TP_approx_avg))+
    geom_abline(slope = -0.01, intercept = 1)+
    #facet_grid(velocity_m.s~tN_approx_avg)+
    #geom_ribbon(data = gam_pred, aes(x = Mass_per_loss, ymin = 1/(fit -2*se.fit), ymax = 1/(fit +2*se.fit)), alpha = 0.3)+
    NULL
N.tp.p
```






```{r}
#Lignin models
#Note, we here again do not want to model the main effect of initial_Lignin, because the intercept is defined by initial_N. however, there can be differences in the mean initial_N mean of different series if they're grouped by, say, lignin. 

N.end.lig <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, initial_Lignin) +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, bs = "re")+s(series_index, Mass_per_loss, bs = "re")  , method = "REML", family = Gamma(link = "log"))#everything intersects in the middle at single point 

N.end.lig2 <- gam(data = det_loc, N_mass ~  s(initial_Lignin) + ti(Mass_per_loss, initial_Lignin) +s(Remain_Mass_Category, Mass_per_loss, bs = "fs") +s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link = "log"))#everything intersects in the middle at single point, had to get rid of random intercept 

N.end.lig3 <- gam(data = det_loc, N_mass ~  s(initial_Lignin) + ti(Mass_per_loss, initial_Lignin) +s(Remain_Mass_Category, Mass_per_loss, bs = "fs"), method = "REML", family = Gamma(link = "log"))#everything intersects in the middle at single point, had to get rid of random slope

N.end.lig4 <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, initial_Lignin) +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")+s(series_index, Mass_per_loss, bs = "re") , method = "REML", family = Gamma(link = "log"))#everything intersects in the middle at single point, had to get rid of random intercept

N.end.lig5 <- gam(data = det_loc, N_mass ~  ti(Mass_per_loss, initial_Lignin) +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")+s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))

N.end.lig6 <- gam(data = det_loc, N_mass ~  s(Mass_per_loss) +  s(initial_Lignin) +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")+s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))

N.end.lig7 <- gam(data = det_loc, N_mass ~  s(initial_Lignin) +s(Remain_Mass_Category, Mass_per_loss, bs = "fs")+s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))

N.end.lig8 <- gam(data = det_loc, N_mass ~  s(initial_Lignin) + ti(Mass_per_loss, initial_Lignin)+s(Remain_Mass_Category, Mass_per_loss, bs = "fs")+s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log")) #random slope with intercept won't fit

AIC(N.end.lig, N.end.lig2, N.end.lig3, N.end.lig4, N.end.lig5, N.end.lig6,N.end.lig7,N.end.lig8) #N.end.lig slightly favored over N.end.lig5 and lig8, and appraise() check is pretty equivalenty between the two models

gam_pred_lig<-predict_gam(type = "link", N.end.lig6,  exclude_terms = c("s(series_index)", "s(series_index, Mass_per_loss)", "s(Remain_Mass_Category, Mass_per_loss)"), values = list(series_index = NULL, initial_Lignin = c(2.5,5,10,15,25,40)))%>%
  mutate(initial_Lignin = as_factor(initial_Lignin))

 N.lig.p<- ggplot()+
  geom_point(data = det_loc, aes(Mass_per_loss, N_mass), alpha = 0.3)+
    geom_smooth(data = gam_pred_lig, aes(x = Mass_per_loss, y = exp(fit), color = initial_Lignin))+
    geom_abline(slope = -0.01, intercept = 1)+
    #facet_grid(velocity_m.s~tN_approx_avg)+
    #geom_ribbon(data = gam_pred, aes(x = Mass_per_loss, ymin = 1/(fit -2*se.fit), ymax = 1/(fit +2*se.fit)), alpha = 0.3)+
    NULL
N.lig.p

```




```{r Lotic Coarse exploratory models - Exo-Endo combined}

```
#N.extn variations = TP, velocity should also receive a separate model to investigate, e.g., its moderation (interaction) on Mass_per_loss

N.end1 <- gam(data = det_loc, N_mass_norm ~ s(Mass_per_loss) + s(initial_N) + s(initial_Lignin) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.endn alternatives gets phenolics, hemicell? initial_P? NP?

N.met1 <- ...needs to be Masscat, basically. continous mesh size?

N.com1 <-

N.loc.tn <- gam(data = det_loc, N_mass_norm ~ s(Mass_per_loss, k = 15) + s(TN_approx) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.loc.tp <- gam(data = det_loc, N_mass_norm ~ s(Mass_per_loss, k = 15) + s(TP_approx) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.loc.vel <- gam(data = det_loc, N_mass_norm ~ s(Mass_per_loss, k = 15) + s(Velocity_m.s) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.loc.ph <- gam(data = det_loc, N_mass_norm ~ s(Mass_per_loss, k = 15) + s(pH) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.loc.lig <- gam(data = det_loc, N_mass_norm ~ s(Mass_per_loss, k = 15) + s(Total_Phenolics_per) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.loc.masscat <- gam(data = det_loc[det_loc$Remain_Mass_Category == "afdm"|det_loc$Remain_Mass_Category == "dm",], N_mass_norm ~ s(Mass_per_loss, Remain_Mass_Category, k = 25, bs = "fs") + Remain_Mass_Category + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.loc.erg <- gam(data = det_loc, N_mass_norm ~ s(Mass_per_loss, k = 15) + s(Ergosterol_ug.g) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.loc.masscattemp <- gam(data = det_loc[det_loc$Remain_Mass_Category == "afdm"|det_loc$Remain_Mass_Category == "dm",], N_mass_norm ~ s(Mass_per_loss, Remain_Mass_Category, k = 15, bs = "fs") + Remain_Mass_Category +s(Temperature_C) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.loc.masscatvel <- gam(data = det_loc[det_loc$Remain_Mass_Category == "afdm"|det_loc$Remain_Mass_Category == "dm",], N_mass_norm ~ s(Mass_per_loss, Remain_Mass_Category, k = 15, bs = "fs") + Remain_Mass_Category +s(Velocity_m.s) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))



summary(N.loc.temp)
summary(N.loc.tn)
summary(N.loc.tp)
summary(N.loc.vel)
summary(N.loc.ph)
summary(N.loc.masscat)
summary(N.loc.erg)
summary(N.loc.masscattemp)



```

```{r}

N.ext <- gam(data = det_loc, N_mass_norm ~ s(initial_N) + s(series_index, bs = "re") + s(series_index, Mass_per_loss, bs = "re"), method = "REML", family = Gamma(link="log"))
summary(N.ext)

 gam_pred.ext<-predict_gam(N.ext, exclude_terms = "s(series_index)",  values = list(initial_N = c(0.3,0.4,0.5, 0.6,0.8, 1,1.5,2.0), Velocity_m.s = c(0.05,0.1,0.2,0.4)))%>% mutate(initial_N = as_factor(initial_N), velocity_m.s = as_factor(Velocity_m.s))


  ggplot()+
  geom_point(data = det_loc, aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_point(data = gam_pred.ext, aes(x = Mass_per_loss, y = exp(fit), color = initial_N))+
    geom_abline(slope = -0.01, intercept = 1)+
    facet_grid(.~velocity_m.s)+
    NULL

```
 
 
 

 ##Coarse Lentic Nmass~initialN


```{r Coarse Lentic only}

det_lec <- det_trim%>%
  filter(mesh_cat == "coarse", Lotic_Lentic == "Lentic")
  det_lec_Nbins <- levels(det_loc$N_bin)
#det_lec<-det_lec%>%
#  mutate(N_bin = fct_recode(N_bin, "very low" = det_lec_Nbins[1], low = det_lec_Nbins[2],  med = det_lec_Nbins[3],  high = #det_lec_Nbins[4], "very high" = det_lec_Nbins[5]))

N.lec.gam <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(initial_N) + ti(Mass_per_loss, initial_N) + s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))

N.lec.gam1 <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(initial_N) + s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))

N.lec.gam2 <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss)+ s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))

N.lec.gam3 <- gam(data = det_lec, N_mass_norm ~ ti(Mass_per_loss, initial_N) + s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))

N.lec.gam4 <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))


gam_pred<-predict_gam(N.lec.gam, exclude_terms = "s(series_index)",  values = list(initial_N = c(0.3,0.4,0.5, 0.6,0.8, 1,1.5,2.0)))%>% mutate(initial_N = as_factor(initial_N))


  ggplot()+
  geom_point(data = det_lec, aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_point(data = gam_pred, aes(x = Mass_per_loss, y = exp(fit), color = initial_N))+
    geom_abline(slope = -0.01, intercept = 1)+
    NULL
  
gam_pred1<-predict_gam(N.lec.gam1, exclude_terms = "s(series_index)",  values = list(initial_N = c(0.3,0.4,0.5, 0.6,0.8, 1,1.5,2.0)))%>% mutate(initial_N = as_factor(initial_N))


  ggplot()+
  geom_point(data = det_lec, aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_point(data = gam_pred1, aes(x = Mass_per_loss, y = exp(fit), color = initial_N))+
    geom_abline(slope = -0.01, intercept = 1)+
    NULL
  
  gam_pred2<-predict_gam(N.lec.gam2, exclude_terms = "s(series_index)")


  ggplot()+
  geom_point(data = det_lec, aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_point(data = gam_pred2, aes(x = Mass_per_loss, y = exp(fit)))+
    geom_abline(slope = -0.01, intercept = 1)+
    NULL
  
gam_pred3<-predict_gam(N.lec.gam3, exclude_terms = "s(series_index)")


  ggplot()+
  geom_point(data = det_lec, aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_point(data = gam_pred3, aes(x = Mass_per_loss, y = exp(fit)))+
    geom_abline(slope = -0.01, intercept = 1)+
    NULL
  
gam_pred4<-predict_gam(N.lec.gam4, exclude_terms = "s(series_index)")


  ggplot()+
  geom_point(data = det_lec, aes(Mass_per_loss, N_mass_norm), alpha = 0.3)+
    geom_point(data = gam_pred4, aes(x = Mass_per_loss, y = exp(fit)))+
    geom_abline(slope = -0.01, intercept = 1)+
    NULL
  
  summary(N.lec.gam)
  appraise(N.lec.gam)
  k.check(N.lec.gam)
  draw(N.lec.gam1)
   summary(N.lec.gam1)
  appraise(N.lec.gam1)
  k.check(N.lec.gam1)
  draw(N.lec.gam2)
     summary(N.lec.gam2)
  appraise(N.lec.gam2)
  k.check(N.lec.gam2)
     summary(N.lec.gam3)
  appraise(N.lec.gam3)
  k.check(N.lec.gam3)
    summary(N.lec.gam4)
  appraise(N.lec.gam4)
  k.check(N.lec.gam4)
  
  
  AIC(N.lec.gam,N.lec.gam1,N.lec.gam2,N.lec.gam3, N.lec.gam4)
```
The MassxInitial N tensor interaction model is not horribly predictive model. However, it is the most parsimonious fit (lowest AIC) of all the base models. But the fit is shit - wonder if that's because the equal initial values on 1 is correlated highly to initial_N or something like that)! Any exploratory models fit better?

## N Mass lentic exploratory modeling
This will be limited compared to lotic analysis thanks to severely decreased sample size.

```{r Lentic Coarse exploratory models}

N.lec.temp <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(Temperature_C) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.lec.tn <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(TN_approx) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.lec.tp <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(TP_approx) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.lec.tpn <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(TP_approx) +s(TN_approx) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

#N.lec.vel <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(Velocity_m.s) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

#N.lec.ph <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(pH) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

#N.lec.lig <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(Total_Phenolics_per) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.lec.masscat <- gam(data = det_lec[det_lec$Remain_Mass_Category == "afdm"|det_lec$Remain_Mass_Category == "dm",], N_mass_norm ~ s(Mass_per_loss, Remain_Mass_Category, bs = "fs") + Remain_Mass_Category + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))


#N.lec.erg <- gam(data = det_lec, N_mass_norm ~ s(Mass_per_loss) + s(Ergosterol_ug.g) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

N.lec.masscattemp <- gam(data = det_lec[det_lec$Remain_Mass_Category == "afdm"|det_lec$Remain_Mass_Category == "dm",], N_mass_norm ~ s(Mass_per_loss, Remain_Mass_Category, bs = "fs") + Remain_Mass_Category +s(Temperature_C) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))

#N.lec.masscatvel <- gam(data = det_lec[det_lec$Remain_Mass_Category == "afdm"|det_lec$Remain_Mass_Category == "dm",], N_mass_norm ~ s(Mass_per_loss, Remain_Mass_Category, bs = "fs") + Remain_Mass_Category +s(Velocity_m.s) + s(series_index, bs = "re"), method = "REML", family = Gamma(link="log"))



summary(N.lec.temp)
summary(N.lec.tn)
summary(N.lec.tp)
#summary(N.lec.vel)
#summary(N.lec.ph)
summary(N.lec.masscat)
#summary(N.lec.erg)
summary(N.lec.masscattemp)


AIC(N.lec.temp, N.lec.tn,N.lec.tp,N.lec.masscat,N.lec.masscattemp)
```
 
 
##N mass lotic-fine modeling 
=======

```{r Lotic - Fine only}

det_lof <- det_trim%>%
  filter(mesh_cat == "fine", Lotic_Lentic == "Lotic")%>%mutate(N_bin = cut_number(initial_N, n = 5))%>%mutate(N_bin = as_factor(N_bin))
det_lof_Nbins <- levels(det_loc$N_bin)
det_lof<-det_lof%>%
  mutate(N_bin = fct_recode(N_bin, "very low" = det_lof_Nbins[1], low = det_lof_Nbins[2],  med = det_lof_Nbins[3],  high = det_lof_Nbins[4], "very high" = det_lof_Nbins[5]))

N.lof.gam <- gam(data = det_lof, N_mass_norm ~ te(Mass_per_loss, initial_N,  bs = "cr") + s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))


gam_pred<-predict_gam(N.lof.gam, exclude_terms = "s(series_index)",  values = list(initial_N = c(0.45,0.7,1.0,2.0,2.5)))%>% mutate(initial_N = as_factor(initial_N))


  
    ggplot()+
  geom_point(data = gam_pred, aes(x = Mass_per_loss, y = exp(fit), color = initial_N))+
  geom_point(data = det_lof, aes(Mass_per_loss, N_mass_norm), alpha = 0.5)+
    scale_x_continuous(limits = c(0,95))+
    scale_y_continuous(limits = c(0,3), breaks = c(0,0.5,1,2))+
    geom_abline(slope = -0.01, intercept = 1)+
    NULL
  
  
   summary(N.lof.gam)
  appraise(N.lof.gam)
  k.check(N.lof.gam)
```

##N mass lentic-fine modeling 
The Lentic-fine model won't fit - not enough data.
```{r Lentic - Fine}

det_lef <- det_trim%>%
  filter(mesh_cat == "fine", Lotic_Lentic == "Lentic")

N.lef.gam <- gam(data = det_lef, N_mass_norm ~ te(Mass_per_loss, initial_N,  bs = "cr") + s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))


gam_pred<-predict_gam(N.lef.gam, exclude_terms = "s(series_index)",  values = list(initial_N = c(0.3,0.4,0.5, 0.6,0.8, 1,1.5,2.0,2.5)))%>% mutate(initial_N = as_factor(initial_N))


  ggplot()+
  geom_point(data = gam_pred, aes(x = Mass_per_loss, y = exp(fit), color = initial_N))+
  geom_point(data = det_lef, aes(Mass_per_loss, N_mass_norm), alpha = 0.05)+
    scale_x_continuous(limits = c(0,95))+
    #facet_grid(.~Lotic_Lentic)+
    scale_y_continuous(limits = c(0,3), breaks = c(0,0.5,1,2))+
    geom_abline(slope = -0.01, intercept = 1)+
    NULL
  
```

##Basic N Mass loss~time models
```{r coarse}


N.lct.gam <- gam(data = det_loc, N_mass_norm ~ s(Meas_Day,Lotic_Lentic, bs = "fs")+s(initial_N, Lotic_Lentic, bs = "fs")+ti(Meas_Day, initial_N,  bs = "cr", by = Lotic_Lentic) + s(series_index, bs = "re"), method = "REML", family = Gamma(link = "log"))


gam_pred<-predict_gam(N.lct.gam, exclude_terms = "s(series_index)",  values = list(initial_N = c(0.3,0.7,1.0,2.0,2.5)))%>% mutate(initial_N = as_factor(initial_N))


  
    ggplot()+
      geom_point(data = det_loc, aes(Meas_Day, N_mass_norm), alpha = 0.5)+
      geom_point(data = gam_pred, aes(x = Meas_Day, y = exp(fit), color = initial_N))+
      facet_grid(.~Lotic_Lentic)+
    #scale_x_continuous(limits = c(0,95))+
      scale_y_continuous(limits = c(0,3), breaks = c(0,0.5,1,2))+
      geom_abline(slope = -0.01, intercept = 1)+
      NULL
    
  
  draw(N.lct.gam)
  summary(N.lct.gam)
  appraise(N.lct.gam)
  k.check(N.lct.gam)
  
```





#P modeling
##Basic P mass loss models
##Basic P mass loss~time models
##Exploratory P mass modeling


#Stoichiometry - could following be separate paper?
This paper could focus on patterns of stoichiometric convergence a la some of Manning papers
Look at results of everything then decide
#CN modeling
##CN mass loss by initial N
##CN exploratory

#CP modeling
##CP mass loss by initial P
##CP exploratory

#NP modeling
##NP exploratory




